{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# univariate multi-step encoder-decoder convlstm for the power usage dataset\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "\n",
    "\n",
    "\n",
    "from keras import Model, layers\n",
    "from keras.models import load_model, model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "    # split into standard weeks\n",
    "    train, test = data[1:-328], data[-328:-6]\n",
    "    # restructure into windows of weekly data\n",
    "    train = array(split(train, len(train)/7))\n",
    "    test = array(split(test, len(test)/7))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = list()\n",
    "    # calculate an RMSE score for each day\n",
    "    for i in range(actual.shape[1]):\n",
    "        # calculate mse\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        # calculate rmse\n",
    "        rmse = sqrt(mse)\n",
    "        scores.append(rmse)\n",
    "    # calculate overall RMSE\n",
    "    s = 0\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=7):\n",
    "    # flatten data\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end < len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def build_and_train_model(train, n_steps, n_length, n_input):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(train, n_input)\n",
    "    # define parameters\n",
    "    verbose, epochs, batch_size = 1, 50, 16\n",
    "    n_features, n_outputs = train_x.shape[2], train_y.shape[1]\n",
    "    # reshape into subsequences [samples, timesteps, rows, cols, channels]\n",
    "    train_x = train_x.reshape((train_x.shape[0], n_steps, 1, n_length, n_features))\n",
    "    # reshape output into [samples, timesteps, features]\n",
    "    train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
    "    model.add(Flatten())\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit network\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a forecast\n",
    "def forecast(model, history, n_steps, n_length, n_input):\n",
    "    # flatten data\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    # retrieve last observations for input data\n",
    "    input_x = data[-n_input:, :]\n",
    "    # reshape into [samples, timesteps, rows, cols, channels]\n",
    "    input_x = input_x.reshape((1, n_steps, 1, n_length, 1))\n",
    "    # forecast the next week\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    # we only want the vector forecast\n",
    "    yhat = yhat[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_steps, n_length, n_input):\n",
    "    # fit model\n",
    "    model = build_and_train_model(train, n_steps, n_length, n_input)\n",
    "    model.save('models/ConvLSTM_Encoder-Decoder_Multivariate_input_Model.h5')\n",
    "\n",
    "    # architecture to JSON, weights to HDF5\n",
    "    model.save_weights('models/ConvLSTM_Encoder-Decoder_Multivariate_input_Model_Weights.h5')\n",
    "    with open('models/ConvLSTM_Encoder-Decoder_Multivariate_input_Model_architecture.json', 'w') as f:\n",
    "            f.write(model.to_json())\n",
    "    # history is a list of weekly data\n",
    "    history = [x for x in train]\n",
    "    # walk-forward validation over each week\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict the week\n",
    "        yhat_sequence = forecast(model, history, n_steps, n_length, n_input)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)\n",
    "        # get real observation and add to history for predicting the next week\n",
    "        history.append(test[i, :])\n",
    "    # evaluate predictions days for each week\n",
    "    predictions = array(predictions)\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    return score, scores\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(train, test, n_steps, n_length, n_input):\n",
    "    # architecture and weights from HDF5\n",
    "    model = load_model('models/ConvLSTM_Encoder-Decoder_Multivariate_input_Model.h5')\n",
    "\n",
    "    # architecture from JSON, weights from HDF5\n",
    "    with open('models/ConvLSTM_Encoder-Decoder_Multivariate_input_Model_architecture.json') as f:\n",
    "        model = model_from_json(f.read())\n",
    "    model.load_weights('models/ConvLSTM_Encoder-Decoder_Multivariate_input_Model_Weights.h5')\n",
    "    \n",
    "    \n",
    "    # history is a list of weekly data\n",
    "    history = [x for x in train]\n",
    "    # walk-forward validation over each week\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict the week\n",
    "        yhat_sequence = forecast(model, history, n_steps, n_length, n_input)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)\n",
    "        # get real observation and add to history for predicting the next week\n",
    "        history.append(test[i, :])\n",
    "    # evaluate predictions days for each week\n",
    "    predictions = array(predictions)\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1092/1092 [==============================] - 9s 8ms/step - loss: 3776838.0595\n",
      "Epoch 2/50\n",
      "1092/1092 [==============================] - 4s 4ms/step - loss: 596202.4924\n",
      "Epoch 3/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 352756.6641\n",
      "Epoch 4/50\n",
      "1092/1092 [==============================] - 6s 5ms/step - loss: 307529.5346\n",
      "Epoch 5/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 315929.7908\n",
      "Epoch 6/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 296673.5094\n",
      "Epoch 7/50\n",
      "1092/1092 [==============================] - 6s 5ms/step - loss: 280025.6609\n",
      "Epoch 8/50\n",
      "1092/1092 [==============================] - 6s 5ms/step - loss: 293370.4195\n",
      "Epoch 9/50\n",
      "1092/1092 [==============================] - 6s 5ms/step - loss: 290735.0902\n",
      "Epoch 10/50\n",
      "1092/1092 [==============================] - 5s 4ms/step - loss: 269575.8071\n",
      "Epoch 11/50\n",
      "1092/1092 [==============================] - 4s 4ms/step - loss: 302627.8587\n",
      "Epoch 12/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 268375.7098\n",
      "Epoch 13/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 264965.8437\n",
      "Epoch 14/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 273755.7059\n",
      "Epoch 15/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 263797.4584\n",
      "Epoch 16/50\n",
      "1092/1092 [==============================] - 5s 4ms/step - loss: 278219.1409\n",
      "Epoch 17/50\n",
      "1092/1092 [==============================] - 7s 7ms/step - loss: 289999.8725\n",
      "Epoch 18/50\n",
      "1092/1092 [==============================] - 6s 5ms/step - loss: 258486.6685\n",
      "Epoch 19/50\n",
      "1092/1092 [==============================] - 4s 4ms/step - loss: 278445.1462\n",
      "Epoch 20/50\n",
      "1092/1092 [==============================] - 4s 4ms/step - loss: 279601.6433\n",
      "Epoch 21/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 288170.7884\n",
      "Epoch 22/50\n",
      "1092/1092 [==============================] - 6s 5ms/step - loss: 264454.2426: 0s - los\n",
      "Epoch 23/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 268977.3014\n",
      "Epoch 24/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 268937.2926\n",
      "Epoch 25/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 257938.0132\n",
      "Epoch 26/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 263207.6077\n",
      "Epoch 27/50\n",
      "1092/1092 [==============================] - 4s 4ms/step - loss: 285268.0013\n",
      "Epoch 28/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 258877.8752\n",
      "Epoch 29/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 256909.5781\n",
      "Epoch 30/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 283016.3332\n",
      "Epoch 31/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 254802.2010\n",
      "Epoch 32/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 256294.8389\n",
      "Epoch 33/50\n",
      "1092/1092 [==============================] - 4s 4ms/step - loss: 270708.9670\n",
      "Epoch 34/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 314555.7679\n",
      "Epoch 35/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 314830.1119\n",
      "Epoch 36/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 254197.6891\n",
      "Epoch 37/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 292650.8149\n",
      "Epoch 38/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 254958.0737\n",
      "Epoch 39/50\n",
      "1092/1092 [==============================] - 5s 4ms/step - loss: 246097.3090\n",
      "Epoch 40/50\n",
      "1092/1092 [==============================] - 4s 4ms/step - loss: 263666.3302\n",
      "Epoch 41/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 262883.1748\n",
      "Epoch 42/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 249743.3444\n",
      "Epoch 43/50\n",
      "1092/1092 [==============================] - 6s 5ms/step - loss: 267353.8192\n",
      "Epoch 44/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 245767.2009\n",
      "Epoch 45/50\n",
      "1092/1092 [==============================] - 6s 5ms/step - loss: 269252.0048\n",
      "Epoch 46/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 248877.9240\n",
      "Epoch 47/50\n",
      "1092/1092 [==============================] - 5s 4ms/step - loss: 252342.2961\n",
      "Epoch 48/50\n",
      "1092/1092 [==============================] - 5s 4ms/step - loss: 245890.0372\n",
      "Epoch 49/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 255486.0362\n",
      "Epoch 50/50\n",
      "1092/1092 [==============================] - 5s 5ms/step - loss: 245197.4983\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 112 into shape (1,2,1,7,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b68370ae2229>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# define the total days to use as input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mn_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_length\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# summarize scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msummarize_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'convlstm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-681af021748c>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(train, test, n_steps, n_length, n_input)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# predict the week\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0myhat_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m# store the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-12a3d2565b7f>\u001b[0m in \u001b[0;36mforecast\u001b[1;34m(model, history, n_steps, n_length, n_input)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0minput_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# reshape into [1, n_input, n]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0minput_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m# forecast the next week\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 112 into shape (1,2,1,7,1)"
     ]
    }
   ],
   "source": [
    "# load the new file\n",
    "dataset = read_csv('smart meter dataset\\household_power_consumption\\household_power_consumption_Naive_Forecast_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# define the number of subsequences and the length of subsequences\n",
    "n_steps, n_length = 2, 7\n",
    "# define the total days to use as input\n",
    "n_input = n_length * n_steps\n",
    "score, scores = evaluate_model(train, test, n_steps, n_length, n_input)\n",
    "# summarize scores\n",
    "summarize_scores('convlstm', score, scores)\n",
    "# plot scores\n",
    "days_label = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "days = [0, 1, 2, 3, 4, 5, 6]\n",
    "pyplot.plot(days, scores, marker='o', label='convlstm')\n",
    "pyplot.xlabel(days_label)\n",
    "pyplot.ylabel(\"RMSE Daily Forecast Error\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 112 into shape (1,2,1,7,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-07939bb0c19a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# define the total days to use as input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_length\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_pretrained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# summarize scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msummarize_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'convlstm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-edfdbc253aa6>\u001b[0m in \u001b[0;36mload_pretrained_model\u001b[1;34m(train, test, n_steps, n_length, n_input)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# predict the week\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0myhat_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m# store the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-cfadd5144917>\u001b[0m in \u001b[0;36mforecast\u001b[1;34m(model, history, n_steps, n_length, n_input)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0minput_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# reshape into [samples, timesteps, rows, cols, channels]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0minput_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# forecast the next week\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 112 into shape (1,2,1,7,1)"
     ]
    }
   ],
   "source": [
    "# load pretrained model and get scores\n",
    "# define the number of subsequences and the length of subsequences\n",
    "n_steps, n_length = 2, 7\n",
    "# define the total days to use as input\n",
    "n_input = n_length * n_steps\n",
    "score, scores = load_pretrained_model(train, test, n_steps, n_length, n_input)\n",
    "# summarize scores\n",
    "summarize_scores('convlstm', score, scores)\n",
    "# plot scores\n",
    "days_label = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "days = [0, 1, 2, 3, 4, 5, 6]\n",
    "pyplot.plot(days, scores, marker='o', label='convlstm')\n",
    "pyplot.xlabel(days_label)\n",
    "pyplot.ylabel(\"RMSE Daily Forecast Error\")\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
